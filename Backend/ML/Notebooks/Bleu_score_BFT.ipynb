{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the datasets\n",
    "df_hindi = pd.read_csv('../Datasets/WikiMatrix/Processed/clean_en-hi.csv')  # Replace with your file path\n",
    "df_greek = pd.read_csv('../Datasets/WikiMatrix/Processed/clean_en-el.csv')  # Replace with your file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hindi = df_hindi.sample(22000, random_state=11)\n",
    "df_greek = df_greek.sample(2200, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "# # Load the datasets\n",
    "# df_hindi = pd.read_csv('../Datasets/WikiMatrix/Processed/clean_en-hi.csv')  # Replace with your file path\n",
    "# df_greek = pd.read_csv('../Datasets/WikiMatrix/Processed/clean_en-el.csv')  # Replace with your file path\n",
    "\n",
    "# Extract source and target texts\n",
    "source_texts_hindi = df_hindi['English'].tolist()\n",
    "target_texts_hindi = df_hindi['Hindi'].tolist()\n",
    "\n",
    "source_texts_greek = df_greek['English'].tolist()\n",
    "target_texts_greek = df_greek['Greek'].tolist()\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"facebook/m2m100_418M\"  # You can use a larger model if needed\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to calculate BLEU score for a dataset\n",
    "def calculate_bleu_score(source_texts, target_texts, model, tokenizer, src_lang, target_lang):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    translated_texts = []\n",
    "    for text in source_texts:\n",
    "        encoded_inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "        generated_tokens = model.generate(**encoded_inputs, forced_bos_token_id=tokenizer.get_lang_id(target_lang))\n",
    "        translated_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "        translated_texts.append(translated_text)\n",
    "    bleu_score = corpus_bleu(translated_texts, [target_texts])\n",
    "    return bleu_score.score\n",
    "\n",
    "# Calculate BLEU scores for both datasets\n",
    "bleu_score_hindi = calculate_bleu_score(source_texts_hindi, target_texts_hindi, model, tokenizer, \"en\", \"hi\")\n",
    "bleu_score_greek = calculate_bleu_score(source_texts_greek, target_texts_greek, model, tokenizer, \"en\", \"el\")\n",
    "\n",
    "print(f\"BLEU score for English-to-Hindi: {bleu_score_hindi}\")\n",
    "print(f\"BLEU score for English-to-Greek: {bleu_score_greek}\")\n",
    "\n",
    "# Plot the BLEU scores\n",
    "languages = ['English-to-Hindi', 'English-to-Greek']\n",
    "bleu_scores = [bleu_score_hindi, bleu_score_greek]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(languages, bleu_scores, color=['blue', 'green'])\n",
    "plt.title('BLEU Score Comparison')\n",
    "plt.xlabel('Language Pair')\n",
    "plt.ylabel('BLEU Score')\n",
    "plt.ylim(0, 100)  # BLEU score ranges from 0 to 100\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
