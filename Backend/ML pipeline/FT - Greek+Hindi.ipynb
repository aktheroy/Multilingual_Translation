{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Third-party library imports\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets, load_dataset\n",
    "from evaluate import load as load_metric\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Transformers and related libraries\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "# LoRA (optional, if you still want to use it)\n",
    "# from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "dataset_english_to_hindi = load_dataset(\n",
    "    \"csv\", data_files={\"train\": \"../Datasets/WikiMatrix/Processed/clean_en-hi.csv\"},\n",
    "    split=\"train[:80000]\"  # Use a subset for faster debugging\n",
    ")\n",
    "\n",
    "dataset_english_to_greek = load_dataset(\n",
    "    \"csv\", data_files={\"train\": \"../Datasets/WikiMatrix/Processed/clean_en-el.csv\"},\n",
    "    split=\"train[:80000]\"  # Use a subset for faster debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdb7e06423a45dd86235a58a83732e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013010a15139430ebc94d1060b61a41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '<hi> as of 2008, 52 params have been deployed.', 'target': '2008 तक , 52 परम को तैनात किया गया है।', 'tgt_lang': 'hi'}\n",
      "{'source': '<hi> she is tasked with ensuring smooth relations between the crew members.', 'target': 'सचेतकों को अपने दल के सदस्यों से घनिष्ठ संबंध बनाए रखना पड़ता है।', 'tgt_lang': 'hi'}\n"
     ]
    }
   ],
   "source": [
    "def preprocess_datasets(dataset1, dataset2, lang1_token, lang2_token, col_mapping1, col_mapping2):\n",
    "    \"\"\"\n",
    "    Preprocess two datasets to rename columns, add language tokens, and combine them.\n",
    "\n",
    "    Args:\n",
    "        dataset1: First dataset.\n",
    "        dataset2: Second dataset.\n",
    "        lang1_token: Language token for dataset1 (e.g., \"hi\" for Hindi).\n",
    "        lang2_token: Language token for dataset2 (e.g., \"el\" for Greek).\n",
    "        col_mapping1: Dictionary mapping for dataset1 column renaming (e.g., {\"English\": \"source\", \"Hindi\": \"target\"}).\n",
    "        col_mapping2: Dictionary mapping for dataset2 column renaming (e.g., {\"English\": \"source\", \"Greek\": \"target\"}).\n",
    "\n",
    "    Returns:\n",
    "        Combined dataset with consistent formatting.\n",
    "    \"\"\"\n",
    "    # Rename columns for the first dataset\n",
    "    dataset1 = dataset1.rename_columns(col_mapping1)\n",
    "\n",
    "    # Add language token to the source column of dataset1\n",
    "    dataset1 = dataset1.map(lambda x: {\"source\": f\"<{lang1_token}> \" + x[\"source\"], \"tgt_lang\": lang1_token})\n",
    "\n",
    "    # Rename columns for the second dataset\n",
    "    dataset2 = dataset2.rename_columns(col_mapping2)\n",
    "\n",
    "    # Add language token to the source column of dataset2\n",
    "    dataset2 = dataset2.map(lambda x: {\"source\": f\"<{lang2_token}> \" + x[\"source\"], \"tgt_lang\": lang2_token})\n",
    "\n",
    "    # Combine both datasets\n",
    "    combined_dataset = concatenate_datasets([dataset1, dataset2])\n",
    "\n",
    "    return combined_dataset\n",
    "\n",
    "# Preprocess and combine datasets\n",
    "combined_dataset = preprocess_datasets(\n",
    "    dataset_english_to_hindi,\n",
    "    dataset_english_to_greek,\n",
    "    lang1_token=\"hi\",\n",
    "    lang2_token=\"el\",\n",
    "    col_mapping1={\"English\": \"source\", \"Hindi\": \"target\"},\n",
    "    col_mapping2={\"English\": \"source\", \"Greek\": \"target\"}\n",
    ")\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "combined_dataset = combined_dataset.shuffle(seed=42)\n",
    "\n",
    "# Verify the result\n",
    "print(combined_dataset[0])  # Should show a sample from the combined dataset with <hi> token\n",
    "print(combined_dataset[-1]) # Should show a sample from the combined dataset with <el> token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['source', 'target', 'tgt_lang'],\n",
      "        num_rows: 128000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['source', 'target', 'tgt_lang'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['source', 'target', 'tgt_lang'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split the combined dataset into train, validation, and test sets\n",
    "train_test_split = combined_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "validation_test_split = train_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Create a DatasetDict\n",
    "final_dataset = DatasetDict({\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"validation\": validation_test_split[\"train\"],\n",
    "    \"test\": validation_test_split[\"test\"]\n",
    "})\n",
    "\n",
    "# Verify the splits\n",
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "model_name = \"facebook/m2m100_418M\"\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "model.gradient_checkpointing_enable()\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Set the source language\n",
    "    tokenizer.src_lang = \"en\"\n",
    "    tokenizer.tgt_lang = examples[\"tgt_lang\"][0]  # Dynamically set the target language based on the dataset\n",
    "\n",
    "    # Tokenize source and target texts\n",
    "    model_inputs = tokenizer(examples[\"source\"], truncation=True)\n",
    "    labels = tokenizer(examples[\"target\"], truncation=True)\n",
    "    \n",
    "    # Add labels to the model inputs\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c95537e110c4894be999acf90b4e959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/128000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36417693142446c3bfc8903e5c60711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ad6d2fa25f434faf45f7df34bbec2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = final_dataset.map(preprocess_function, batched=True, remove_columns=[\"source\", \"target\", \"tgt_lang\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model,pad_to_multiple_of=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",       # Save model checkpoints per epoch\n",
    "    num_train_epochs=10,         # Total epochs\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    fp16=False,                  # Disable FP16 for MacBook\n",
    "    logging_dir=\"./logs\",        # Directory for TensorBoard logs\n",
    "    logging_steps=50,            # Log every 10 steps\n",
    "    save_total_limit=3,          # Limit to 3 checkpoints\n",
    "    predict_with_generate=True,\n",
    "    report_to=None,              # No integration with external tools\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/kp7y6dd95y992q9stm3w11p80000gn/T/ipykernel_35649/559389546.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,                          # The model to fine-tune\n",
    "    args=training_args,                   # Training configuration\n",
    "    train_dataset=tokenized_dataset[\"train\"],  # Training dataset\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],  # Validation dataset\n",
    "    tokenizer=tokenizer,                  # Tokenizer\n",
    "    data_collator=data_collator,          # Data collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0410afd488a495da144ff26e3299c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6203, 'grad_norm': 51.84031295776367, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.05}\n",
      "{'loss': 1.4118, 'grad_norm': 22.80968475341797, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 1.2238, 'grad_norm': 21.809968948364258, 'learning_rate': 6e-06, 'epoch': 0.15}\n",
      "{'loss': 1.1933, 'grad_norm': 21.529052734375, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 1.1751, 'grad_norm': 22.904752731323242, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.1592, 'grad_norm': 20.255441665649414, 'learning_rate': 1.2e-05, 'epoch': 0.3}\n",
      "{'loss': 1.1569, 'grad_norm': 20.20372772216797, 'learning_rate': 1.4e-05, 'epoch': 0.35}\n",
      "{'loss': 1.1433, 'grad_norm': 21.514604568481445, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.4}\n",
      "{'loss': 1.1337, 'grad_norm': 20.750478744506836, 'learning_rate': 1.8e-05, 'epoch': 0.45}\n",
      "{'loss': 1.1258, 'grad_norm': 20.026456832885742, 'learning_rate': 2e-05, 'epoch': 0.5}\n",
      "{'loss': 1.1279, 'grad_norm': 20.521411895751953, 'learning_rate': 1.9894736842105265e-05, 'epoch': 0.55}\n",
      "{'loss': 1.117, 'grad_norm': 20.998958587646484, 'learning_rate': 1.9789473684210528e-05, 'epoch': 0.6}\n",
      "{'loss': 1.0981, 'grad_norm': 19.857521057128906, 'learning_rate': 1.968421052631579e-05, 'epoch': 0.65}\n",
      "{'loss': 1.0979, 'grad_norm': 19.855127334594727, 'learning_rate': 1.9578947368421055e-05, 'epoch': 0.7}\n",
      "{'loss': 1.1016, 'grad_norm': 20.53299903869629, 'learning_rate': 1.9473684210526318e-05, 'epoch': 0.75}\n",
      "{'loss': 1.0878, 'grad_norm': 20.340147018432617, 'learning_rate': 1.936842105263158e-05, 'epoch': 0.8}\n",
      "{'loss': 1.1005, 'grad_norm': 20.014713287353516, 'learning_rate': 1.9263157894736845e-05, 'epoch': 0.85}\n",
      "{'loss': 1.0998, 'grad_norm': 20.121170043945312, 'learning_rate': 1.9157894736842108e-05, 'epoch': 0.9}\n",
      "{'loss': 1.0852, 'grad_norm': 20.765869140625, 'learning_rate': 1.9052631578947368e-05, 'epoch': 0.95}\n",
      "{'loss': 1.0672, 'grad_norm': 20.22988510131836, 'learning_rate': 1.894736842105263e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaa09afcc2d40eab8feae78e082f41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9845430850982666, 'eval_runtime': 221.8368, 'eval_samples_per_second': 72.125, 'eval_steps_per_second': 9.016, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theakroy/miniforge3/envs/Mlx/lib/python3.12/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0341, 'grad_norm': 19.889404296875, 'learning_rate': 1.8842105263157898e-05, 'epoch': 1.05}\n",
      "{'loss': 1.0101, 'grad_norm': 18.472627639770508, 'learning_rate': 1.873684210526316e-05, 'epoch': 1.1}\n",
      "{'loss': 1.0149, 'grad_norm': 18.797931671142578, 'learning_rate': 1.8631578947368424e-05, 'epoch': 1.15}\n",
      "{'loss': 1.0308, 'grad_norm': 20.70826530456543, 'learning_rate': 1.8526315789473684e-05, 'epoch': 1.2}\n",
      "{'loss': 1.0096, 'grad_norm': 18.492034912109375, 'learning_rate': 1.8421052631578947e-05, 'epoch': 1.25}\n",
      "{'loss': 0.9994, 'grad_norm': 19.457138061523438, 'learning_rate': 1.831578947368421e-05, 'epoch': 1.3}\n",
      "{'loss': 1.0016, 'grad_norm': 19.335248947143555, 'learning_rate': 1.8210526315789477e-05, 'epoch': 1.35}\n",
      "{'loss': 1.0106, 'grad_norm': 16.963558197021484, 'learning_rate': 1.810526315789474e-05, 'epoch': 1.4}\n",
      "{'loss': 0.9895, 'grad_norm': 19.457237243652344, 'learning_rate': 1.8e-05, 'epoch': 1.45}\n",
      "{'loss': 1.0039, 'grad_norm': 19.460041046142578, 'learning_rate': 1.7894736842105264e-05, 'epoch': 1.5}\n",
      "{'loss': 1.0208, 'grad_norm': 18.164352416992188, 'learning_rate': 1.7789473684210527e-05, 'epoch': 1.55}\n",
      "{'loss': 1.0018, 'grad_norm': 18.156999588012695, 'learning_rate': 1.768421052631579e-05, 'epoch': 1.6}\n",
      "{'loss': 1.0093, 'grad_norm': 18.695987701416016, 'learning_rate': 1.7578947368421054e-05, 'epoch': 1.65}\n",
      "{'loss': 0.9949, 'grad_norm': 18.82411003112793, 'learning_rate': 1.7473684210526317e-05, 'epoch': 1.7}\n",
      "{'loss': 0.9988, 'grad_norm': 17.675174713134766, 'learning_rate': 1.736842105263158e-05, 'epoch': 1.75}\n",
      "{'loss': 0.9982, 'grad_norm': 19.830018997192383, 'learning_rate': 1.7263157894736843e-05, 'epoch': 1.8}\n",
      "{'loss': 0.9885, 'grad_norm': 18.29461669921875, 'learning_rate': 1.7157894736842107e-05, 'epoch': 1.85}\n",
      "{'loss': 1.0173, 'grad_norm': 19.113473892211914, 'learning_rate': 1.705263157894737e-05, 'epoch': 1.9}\n",
      "{'loss': 0.9951, 'grad_norm': 18.7655086517334, 'learning_rate': 1.6947368421052633e-05, 'epoch': 1.95}\n",
      "{'loss': 0.9952, 'grad_norm': 18.811798095703125, 'learning_rate': 1.6842105263157896e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689e86215ae34e32ab295797e96e6152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9439496994018555, 'eval_runtime': 221.7308, 'eval_samples_per_second': 72.16, 'eval_steps_per_second': 9.02, 'epoch': 2.0}\n",
      "{'loss': 0.9296, 'grad_norm': 18.361976623535156, 'learning_rate': 1.673684210526316e-05, 'epoch': 2.05}\n",
      "{'loss': 0.9379, 'grad_norm': 18.08510971069336, 'learning_rate': 1.6631578947368423e-05, 'epoch': 2.1}\n",
      "{'loss': 0.922, 'grad_norm': 17.74725914001465, 'learning_rate': 1.6526315789473686e-05, 'epoch': 2.15}\n",
      "{'loss': 0.9418, 'grad_norm': 18.898895263671875, 'learning_rate': 1.642105263157895e-05, 'epoch': 2.2}\n",
      "{'loss': 0.925, 'grad_norm': 18.823726654052734, 'learning_rate': 1.6315789473684213e-05, 'epoch': 2.25}\n",
      "{'loss': 0.9273, 'grad_norm': 18.835203170776367, 'learning_rate': 1.6210526315789473e-05, 'epoch': 2.3}\n",
      "{'loss': 0.9248, 'grad_norm': 18.476179122924805, 'learning_rate': 1.6105263157894736e-05, 'epoch': 2.35}\n",
      "{'loss': 0.9269, 'grad_norm': 18.535886764526367, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.4}\n",
      "{'loss': 0.9265, 'grad_norm': 17.761371612548828, 'learning_rate': 1.5894736842105266e-05, 'epoch': 2.45}\n",
      "{'loss': 0.9245, 'grad_norm': 17.728118896484375, 'learning_rate': 1.578947368421053e-05, 'epoch': 2.5}\n",
      "{'loss': 0.9295, 'grad_norm': 18.328027725219727, 'learning_rate': 1.568421052631579e-05, 'epoch': 2.55}\n",
      "{'loss': 0.9491, 'grad_norm': 19.230138778686523, 'learning_rate': 1.5578947368421052e-05, 'epoch': 2.6}\n",
      "{'loss': 0.9298, 'grad_norm': 18.276899337768555, 'learning_rate': 1.5473684210526316e-05, 'epoch': 2.65}\n",
      "{'loss': 0.9331, 'grad_norm': 18.484086990356445, 'learning_rate': 1.536842105263158e-05, 'epoch': 2.7}\n",
      "{'loss': 0.9216, 'grad_norm': 17.970212936401367, 'learning_rate': 1.5263157894736846e-05, 'epoch': 2.75}\n",
      "{'loss': 0.9364, 'grad_norm': 18.58357048034668, 'learning_rate': 1.5157894736842107e-05, 'epoch': 2.8}\n",
      "{'loss': 0.9343, 'grad_norm': 18.97541618347168, 'learning_rate': 1.505263157894737e-05, 'epoch': 2.85}\n",
      "{'loss': 0.9194, 'grad_norm': 19.36021614074707, 'learning_rate': 1.4947368421052632e-05, 'epoch': 2.9}\n",
      "{'loss': 0.9304, 'grad_norm': 17.819599151611328, 'learning_rate': 1.4842105263157895e-05, 'epoch': 2.95}\n",
      "{'loss': 0.9339, 'grad_norm': 17.791383743286133, 'learning_rate': 1.4736842105263159e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23d196cf0b1456f80f3c740f1780136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.92531418800354, 'eval_runtime': 234.265, 'eval_samples_per_second': 68.299, 'eval_steps_per_second': 8.537, 'epoch': 3.0}\n",
      "{'loss': 0.8726, 'grad_norm': 18.03898048400879, 'learning_rate': 1.4631578947368424e-05, 'epoch': 3.05}\n",
      "{'loss': 0.8749, 'grad_norm': 18.282928466796875, 'learning_rate': 1.4526315789473687e-05, 'epoch': 3.1}\n",
      "{'loss': 0.8645, 'grad_norm': 16.716835021972656, 'learning_rate': 1.4421052631578948e-05, 'epoch': 3.15}\n",
      "{'loss': 0.8774, 'grad_norm': 18.056316375732422, 'learning_rate': 1.4315789473684212e-05, 'epoch': 3.2}\n",
      "{'loss': 0.8839, 'grad_norm': 17.766489028930664, 'learning_rate': 1.4210526315789475e-05, 'epoch': 3.25}\n",
      "{'loss': 0.8814, 'grad_norm': 19.41548728942871, 'learning_rate': 1.4105263157894738e-05, 'epoch': 3.3}\n",
      "{'loss': 0.8792, 'grad_norm': 17.543310165405273, 'learning_rate': 1.4e-05, 'epoch': 3.35}\n",
      "{'loss': 0.8854, 'grad_norm': 18.45050811767578, 'learning_rate': 1.3894736842105265e-05, 'epoch': 3.4}\n",
      "{'loss': 0.8794, 'grad_norm': 17.89935302734375, 'learning_rate': 1.3789473684210528e-05, 'epoch': 3.45}\n",
      "{'loss': 0.885, 'grad_norm': 19.51198387145996, 'learning_rate': 1.3684210526315791e-05, 'epoch': 3.5}\n",
      "{'loss': 0.8849, 'grad_norm': 18.75798988342285, 'learning_rate': 1.3578947368421055e-05, 'epoch': 3.55}\n",
      "{'loss': 0.869, 'grad_norm': 18.096118927001953, 'learning_rate': 1.3473684210526316e-05, 'epoch': 3.6}\n",
      "{'loss': 0.8804, 'grad_norm': 18.456090927124023, 'learning_rate': 1.336842105263158e-05, 'epoch': 3.65}\n",
      "{'loss': 0.8758, 'grad_norm': 17.78606414794922, 'learning_rate': 1.3263157894736843e-05, 'epoch': 3.7}\n",
      "{'loss': 0.8785, 'grad_norm': 16.830917358398438, 'learning_rate': 1.3157894736842108e-05, 'epoch': 3.75}\n",
      "{'loss': 0.873, 'grad_norm': 18.36037254333496, 'learning_rate': 1.305263157894737e-05, 'epoch': 3.8}\n",
      "{'loss': 0.8796, 'grad_norm': 20.550500869750977, 'learning_rate': 1.2947368421052633e-05, 'epoch': 3.85}\n",
      "{'loss': 0.8796, 'grad_norm': 19.395572662353516, 'learning_rate': 1.2842105263157896e-05, 'epoch': 3.9}\n",
      "{'loss': 0.8565, 'grad_norm': 17.736631393432617, 'learning_rate': 1.2736842105263159e-05, 'epoch': 3.95}\n",
      "{'loss': 0.883, 'grad_norm': 17.648792266845703, 'learning_rate': 1.263157894736842e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898c0fabfeaa4d93bbbe48fdb727ce6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9124051332473755, 'eval_runtime': 235.7135, 'eval_samples_per_second': 67.879, 'eval_steps_per_second': 8.485, 'epoch': 4.0}\n",
      "{'loss': 0.8452, 'grad_norm': 17.841787338256836, 'learning_rate': 1.2526315789473684e-05, 'epoch': 4.05}\n",
      "{'loss': 0.8252, 'grad_norm': 19.776287078857422, 'learning_rate': 1.2421052631578949e-05, 'epoch': 4.1}\n",
      "{'loss': 0.8291, 'grad_norm': 16.880905151367188, 'learning_rate': 1.2315789473684212e-05, 'epoch': 4.15}\n",
      "{'loss': 0.8463, 'grad_norm': 18.04164695739746, 'learning_rate': 1.2210526315789475e-05, 'epoch': 4.2}\n",
      "{'loss': 0.8435, 'grad_norm': 18.85912322998047, 'learning_rate': 1.2105263157894737e-05, 'epoch': 4.25}\n",
      "{'loss': 0.8421, 'grad_norm': 19.50041389465332, 'learning_rate': 1.2e-05, 'epoch': 4.3}\n",
      "{'loss': 0.8359, 'grad_norm': 17.628496170043945, 'learning_rate': 1.1894736842105264e-05, 'epoch': 4.35}\n",
      "{'loss': 0.8308, 'grad_norm': 16.655805587768555, 'learning_rate': 1.1789473684210527e-05, 'epoch': 4.4}\n",
      "{'loss': 0.8275, 'grad_norm': 16.969255447387695, 'learning_rate': 1.1684210526315792e-05, 'epoch': 4.45}\n",
      "{'loss': 0.8292, 'grad_norm': 17.58488655090332, 'learning_rate': 1.1578947368421053e-05, 'epoch': 4.5}\n",
      "{'loss': 0.8461, 'grad_norm': 18.101272583007812, 'learning_rate': 1.1473684210526317e-05, 'epoch': 4.55}\n",
      "{'loss': 0.8362, 'grad_norm': 18.017974853515625, 'learning_rate': 1.136842105263158e-05, 'epoch': 4.6}\n",
      "{'loss': 0.8307, 'grad_norm': 17.81673812866211, 'learning_rate': 1.1263157894736843e-05, 'epoch': 4.65}\n",
      "{'loss': 0.8405, 'grad_norm': 18.12917137145996, 'learning_rate': 1.1157894736842105e-05, 'epoch': 4.7}\n",
      "{'loss': 0.829, 'grad_norm': 18.151729583740234, 'learning_rate': 1.105263157894737e-05, 'epoch': 4.75}\n",
      "{'loss': 0.8435, 'grad_norm': 17.541162490844727, 'learning_rate': 1.0947368421052633e-05, 'epoch': 4.8}\n",
      "{'loss': 0.8436, 'grad_norm': 19.510366439819336, 'learning_rate': 1.0842105263157896e-05, 'epoch': 4.85}\n",
      "{'loss': 0.8441, 'grad_norm': 19.621503829956055, 'learning_rate': 1.073684210526316e-05, 'epoch': 4.9}\n",
      "{'loss': 0.8356, 'grad_norm': 19.179161071777344, 'learning_rate': 1.0631578947368421e-05, 'epoch': 4.95}\n",
      "{'loss': 0.8325, 'grad_norm': 17.58306121826172, 'learning_rate': 1.0526315789473684e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e570f619864f41cba791dc73ab964170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9073100686073303, 'eval_runtime': 242.9161, 'eval_samples_per_second': 65.866, 'eval_steps_per_second': 8.233, 'epoch': 5.0}\n",
      "{'loss': 0.7967, 'grad_norm': 16.750539779663086, 'learning_rate': 1.0421052631578948e-05, 'epoch': 5.05}\n",
      "{'loss': 0.7922, 'grad_norm': 18.10331916809082, 'learning_rate': 1.0315789473684213e-05, 'epoch': 5.1}\n",
      "{'loss': 0.799, 'grad_norm': 17.62315559387207, 'learning_rate': 1.0210526315789476e-05, 'epoch': 5.15}\n",
      "{'loss': 0.7853, 'grad_norm': 17.476232528686523, 'learning_rate': 1.0105263157894738e-05, 'epoch': 5.2}\n",
      "{'loss': 0.8115, 'grad_norm': 19.356128692626953, 'learning_rate': 1e-05, 'epoch': 5.25}\n",
      "{'loss': 0.8072, 'grad_norm': 17.135086059570312, 'learning_rate': 9.894736842105264e-06, 'epoch': 5.3}\n",
      "{'loss': 0.8134, 'grad_norm': 18.62698745727539, 'learning_rate': 9.789473684210527e-06, 'epoch': 5.35}\n",
      "{'loss': 0.8127, 'grad_norm': 17.185853958129883, 'learning_rate': 9.68421052631579e-06, 'epoch': 5.4}\n",
      "{'loss': 0.808, 'grad_norm': 16.5694522857666, 'learning_rate': 9.578947368421054e-06, 'epoch': 5.45}\n",
      "{'loss': 0.8112, 'grad_norm': 18.034475326538086, 'learning_rate': 9.473684210526315e-06, 'epoch': 5.5}\n",
      "{'loss': 0.8048, 'grad_norm': 16.989248275756836, 'learning_rate': 9.36842105263158e-06, 'epoch': 5.55}\n",
      "{'loss': 0.8018, 'grad_norm': 17.378860473632812, 'learning_rate': 9.263157894736842e-06, 'epoch': 5.6}\n",
      "{'loss': 0.8144, 'grad_norm': 20.54814910888672, 'learning_rate': 9.157894736842105e-06, 'epoch': 5.65}\n",
      "{'loss': 0.8091, 'grad_norm': 16.941064834594727, 'learning_rate': 9.05263157894737e-06, 'epoch': 5.7}\n",
      "{'loss': 0.8081, 'grad_norm': 17.93735122680664, 'learning_rate': 8.947368421052632e-06, 'epoch': 5.75}\n",
      "{'loss': 0.8042, 'grad_norm': 18.438138961791992, 'learning_rate': 8.842105263157895e-06, 'epoch': 5.8}\n",
      "{'loss': 0.8032, 'grad_norm': 16.740886688232422, 'learning_rate': 8.736842105263158e-06, 'epoch': 5.85}\n",
      "{'loss': 0.7982, 'grad_norm': 18.524869918823242, 'learning_rate': 8.631578947368422e-06, 'epoch': 5.9}\n",
      "{'loss': 0.8029, 'grad_norm': 17.755733489990234, 'learning_rate': 8.526315789473685e-06, 'epoch': 5.95}\n",
      "{'loss': 0.7965, 'grad_norm': 18.240705490112305, 'learning_rate': 8.421052631578948e-06, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fdcea3fa35415fbc47c9ebaa7710c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9005177617073059, 'eval_runtime': 222.2213, 'eval_samples_per_second': 72.0, 'eval_steps_per_second': 9.0, 'epoch': 6.0}\n",
      "{'loss': 0.7743, 'grad_norm': 16.572776794433594, 'learning_rate': 8.315789473684212e-06, 'epoch': 6.05}\n",
      "{'loss': 0.7772, 'grad_norm': 18.729717254638672, 'learning_rate': 8.210526315789475e-06, 'epoch': 6.1}\n",
      "{'loss': 0.7637, 'grad_norm': 18.851781845092773, 'learning_rate': 8.105263157894736e-06, 'epoch': 6.15}\n",
      "{'loss': 0.7675, 'grad_norm': 17.560155868530273, 'learning_rate': 8.000000000000001e-06, 'epoch': 6.2}\n",
      "{'loss': 0.7805, 'grad_norm': 17.89071273803711, 'learning_rate': 7.894736842105265e-06, 'epoch': 6.25}\n",
      "{'loss': 0.7826, 'grad_norm': 17.92136573791504, 'learning_rate': 7.789473684210526e-06, 'epoch': 6.3}\n",
      "{'loss': 0.787, 'grad_norm': 17.540565490722656, 'learning_rate': 7.68421052631579e-06, 'epoch': 6.35}\n",
      "{'loss': 0.7772, 'grad_norm': 18.792987823486328, 'learning_rate': 7.578947368421054e-06, 'epoch': 6.4}\n",
      "{'loss': 0.7787, 'grad_norm': 17.18484878540039, 'learning_rate': 7.473684210526316e-06, 'epoch': 6.45}\n",
      "{'loss': 0.7793, 'grad_norm': 16.057355880737305, 'learning_rate': 7.368421052631579e-06, 'epoch': 6.5}\n",
      "{'loss': 0.7838, 'grad_norm': 18.29460334777832, 'learning_rate': 7.263157894736843e-06, 'epoch': 6.55}\n",
      "{'loss': 0.7756, 'grad_norm': 17.59364128112793, 'learning_rate': 7.157894736842106e-06, 'epoch': 6.6}\n",
      "{'loss': 0.7881, 'grad_norm': 17.657615661621094, 'learning_rate': 7.052631578947369e-06, 'epoch': 6.65}\n",
      "{'loss': 0.7874, 'grad_norm': 19.656450271606445, 'learning_rate': 6.947368421052632e-06, 'epoch': 6.7}\n",
      "{'loss': 0.7832, 'grad_norm': 20.71229362487793, 'learning_rate': 6.842105263157896e-06, 'epoch': 6.75}\n",
      "{'loss': 0.7821, 'grad_norm': 16.91179847717285, 'learning_rate': 6.736842105263158e-06, 'epoch': 6.8}\n",
      "{'loss': 0.7632, 'grad_norm': 17.820852279663086, 'learning_rate': 6.631578947368421e-06, 'epoch': 6.85}\n",
      "{'loss': 0.7778, 'grad_norm': 17.690465927124023, 'learning_rate': 6.526315789473685e-06, 'epoch': 6.9}\n",
      "{'loss': 0.7896, 'grad_norm': 17.657562255859375, 'learning_rate': 6.421052631578948e-06, 'epoch': 6.95}\n",
      "{'loss': 0.7763, 'grad_norm': 17.288623809814453, 'learning_rate': 6.31578947368421e-06, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d53b9d287a549728d5c69947cdc0dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.899794340133667, 'eval_runtime': 220.5854, 'eval_samples_per_second': 72.534, 'eval_steps_per_second': 9.067, 'epoch': 7.0}\n",
      "{'loss': 0.7522, 'grad_norm': 16.98540496826172, 'learning_rate': 6.2105263157894745e-06, 'epoch': 7.05}\n",
      "{'loss': 0.7565, 'grad_norm': 19.03006935119629, 'learning_rate': 6.105263157894738e-06, 'epoch': 7.1}\n",
      "{'loss': 0.7516, 'grad_norm': 18.728172302246094, 'learning_rate': 6e-06, 'epoch': 7.15}\n",
      "{'loss': 0.7578, 'grad_norm': 17.814823150634766, 'learning_rate': 5.8947368421052634e-06, 'epoch': 7.2}\n",
      "{'loss': 0.7469, 'grad_norm': 16.541528701782227, 'learning_rate': 5.789473684210527e-06, 'epoch': 7.25}\n",
      "{'loss': 0.7487, 'grad_norm': 17.722572326660156, 'learning_rate': 5.68421052631579e-06, 'epoch': 7.3}\n",
      "{'loss': 0.7636, 'grad_norm': 17.234554290771484, 'learning_rate': 5.578947368421052e-06, 'epoch': 7.35}\n",
      "{'loss': 0.7616, 'grad_norm': 18.095537185668945, 'learning_rate': 5.4736842105263165e-06, 'epoch': 7.4}\n",
      "{'loss': 0.7533, 'grad_norm': 17.81291961669922, 'learning_rate': 5.36842105263158e-06, 'epoch': 7.45}\n",
      "{'loss': 0.7581, 'grad_norm': 17.291522979736328, 'learning_rate': 5.263157894736842e-06, 'epoch': 7.5}\n",
      "{'loss': 0.772, 'grad_norm': 18.51738166809082, 'learning_rate': 5.157894736842106e-06, 'epoch': 7.55}\n",
      "{'loss': 0.7682, 'grad_norm': 19.106882095336914, 'learning_rate': 5.052631578947369e-06, 'epoch': 7.6}\n",
      "{'loss': 0.755, 'grad_norm': 16.390981674194336, 'learning_rate': 4.947368421052632e-06, 'epoch': 7.65}\n",
      "{'loss': 0.7454, 'grad_norm': 17.187171936035156, 'learning_rate': 4.842105263157895e-06, 'epoch': 7.7}\n",
      "{'loss': 0.7678, 'grad_norm': 18.016708374023438, 'learning_rate': 4.736842105263158e-06, 'epoch': 7.75}\n",
      "{'loss': 0.7625, 'grad_norm': 17.880252838134766, 'learning_rate': 4.631578947368421e-06, 'epoch': 7.8}\n",
      "{'loss': 0.7675, 'grad_norm': 18.60049819946289, 'learning_rate': 4.526315789473685e-06, 'epoch': 7.85}\n",
      "{'loss': 0.7456, 'grad_norm': 17.998214721679688, 'learning_rate': 4.4210526315789476e-06, 'epoch': 7.9}\n",
      "{'loss': 0.7753, 'grad_norm': 17.70742416381836, 'learning_rate': 4.315789473684211e-06, 'epoch': 7.95}\n",
      "{'loss': 0.7561, 'grad_norm': 17.350364685058594, 'learning_rate': 4.210526315789474e-06, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3448aa5ce44f4132bbd91e8296d91f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8988119959831238, 'eval_runtime': 221.7244, 'eval_samples_per_second': 72.162, 'eval_steps_per_second': 9.02, 'epoch': 8.0}\n",
      "{'loss': 0.7404, 'grad_norm': 17.93016242980957, 'learning_rate': 4.105263157894737e-06, 'epoch': 8.05}\n",
      "{'loss': 0.7371, 'grad_norm': 18.42850685119629, 'learning_rate': 4.000000000000001e-06, 'epoch': 8.1}\n",
      "{'loss': 0.7426, 'grad_norm': 19.434194564819336, 'learning_rate': 3.894736842105263e-06, 'epoch': 8.15}\n",
      "{'loss': 0.7392, 'grad_norm': 19.388946533203125, 'learning_rate': 3.789473684210527e-06, 'epoch': 8.2}\n",
      "{'loss': 0.7328, 'grad_norm': 16.429262161254883, 'learning_rate': 3.6842105263157896e-06, 'epoch': 8.25}\n",
      "{'loss': 0.7329, 'grad_norm': 18.328954696655273, 'learning_rate': 3.578947368421053e-06, 'epoch': 8.3}\n",
      "{'loss': 0.7494, 'grad_norm': 18.4221248626709, 'learning_rate': 3.473684210526316e-06, 'epoch': 8.35}\n",
      "{'loss': 0.7384, 'grad_norm': 17.616933822631836, 'learning_rate': 3.368421052631579e-06, 'epoch': 8.4}\n",
      "{'loss': 0.7475, 'grad_norm': 19.29854965209961, 'learning_rate': 3.2631578947368423e-06, 'epoch': 8.45}\n",
      "{'loss': 0.757, 'grad_norm': 19.130634307861328, 'learning_rate': 3.157894736842105e-06, 'epoch': 8.5}\n",
      "{'loss': 0.7443, 'grad_norm': 19.24357032775879, 'learning_rate': 3.052631578947369e-06, 'epoch': 8.55}\n",
      "{'loss': 0.7401, 'grad_norm': 16.522594451904297, 'learning_rate': 2.9473684210526317e-06, 'epoch': 8.6}\n",
      "{'loss': 0.7449, 'grad_norm': 18.365400314331055, 'learning_rate': 2.842105263157895e-06, 'epoch': 8.65}\n",
      "{'loss': 0.7394, 'grad_norm': 17.71072006225586, 'learning_rate': 2.7368421052631583e-06, 'epoch': 8.7}\n",
      "{'loss': 0.745, 'grad_norm': 17.588661193847656, 'learning_rate': 2.631578947368421e-06, 'epoch': 8.75}\n",
      "{'loss': 0.7522, 'grad_norm': 17.709707260131836, 'learning_rate': 2.5263157894736844e-06, 'epoch': 8.8}\n",
      "{'loss': 0.7406, 'grad_norm': 17.103832244873047, 'learning_rate': 2.4210526315789477e-06, 'epoch': 8.85}\n",
      "{'loss': 0.7483, 'grad_norm': 17.312355041503906, 'learning_rate': 2.3157894736842105e-06, 'epoch': 8.9}\n",
      "{'loss': 0.7585, 'grad_norm': 17.501361846923828, 'learning_rate': 2.2105263157894738e-06, 'epoch': 8.95}\n",
      "{'loss': 0.7411, 'grad_norm': 17.495325088500977, 'learning_rate': 2.105263157894737e-06, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4c14fa51294097b84cd2074d5c6d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8991617560386658, 'eval_runtime': 228.0078, 'eval_samples_per_second': 70.173, 'eval_steps_per_second': 8.772, 'epoch': 9.0}\n",
      "{'loss': 0.7305, 'grad_norm': 16.74913787841797, 'learning_rate': 2.0000000000000003e-06, 'epoch': 9.05}\n",
      "{'loss': 0.7253, 'grad_norm': 17.04001808166504, 'learning_rate': 1.8947368421052634e-06, 'epoch': 9.1}\n",
      "{'loss': 0.7267, 'grad_norm': 17.871292114257812, 'learning_rate': 1.7894736842105265e-06, 'epoch': 9.15}\n",
      "{'loss': 0.7393, 'grad_norm': 18.500925064086914, 'learning_rate': 1.6842105263157895e-06, 'epoch': 9.2}\n",
      "{'loss': 0.7169, 'grad_norm': 19.191768646240234, 'learning_rate': 1.5789473684210526e-06, 'epoch': 9.25}\n",
      "{'loss': 0.7267, 'grad_norm': 16.805835723876953, 'learning_rate': 1.4736842105263159e-06, 'epoch': 9.3}\n",
      "{'loss': 0.7413, 'grad_norm': 18.04779815673828, 'learning_rate': 1.3684210526315791e-06, 'epoch': 9.35}\n",
      "{'loss': 0.7414, 'grad_norm': 18.67582130432129, 'learning_rate': 1.2631578947368422e-06, 'epoch': 9.4}\n",
      "{'loss': 0.7236, 'grad_norm': 17.50310707092285, 'learning_rate': 1.1578947368421053e-06, 'epoch': 9.45}\n",
      "{'loss': 0.7338, 'grad_norm': 17.0196475982666, 'learning_rate': 1.0526315789473685e-06, 'epoch': 9.5}\n",
      "{'loss': 0.733, 'grad_norm': 18.011119842529297, 'learning_rate': 9.473684210526317e-07, 'epoch': 9.55}\n",
      "{'loss': 0.7338, 'grad_norm': 17.43092918395996, 'learning_rate': 8.421052631578948e-07, 'epoch': 9.6}\n",
      "{'loss': 0.7323, 'grad_norm': 18.330148696899414, 'learning_rate': 7.368421052631579e-07, 'epoch': 9.65}\n",
      "{'loss': 0.7314, 'grad_norm': 17.514719009399414, 'learning_rate': 6.315789473684211e-07, 'epoch': 9.7}\n",
      "{'loss': 0.7427, 'grad_norm': 17.3327693939209, 'learning_rate': 5.263157894736843e-07, 'epoch': 9.75}\n",
      "{'loss': 0.7251, 'grad_norm': 16.84225845336914, 'learning_rate': 4.210526315789474e-07, 'epoch': 9.8}\n",
      "{'loss': 0.7375, 'grad_norm': 18.094362258911133, 'learning_rate': 3.1578947368421055e-07, 'epoch': 9.85}\n",
      "{'loss': 0.7341, 'grad_norm': 18.215356826782227, 'learning_rate': 2.105263157894737e-07, 'epoch': 9.9}\n",
      "{'loss': 0.7412, 'grad_norm': 19.169692993164062, 'learning_rate': 1.0526315789473685e-07, 'epoch': 9.95}\n",
      "{'loss': 0.7406, 'grad_norm': 17.546092987060547, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b17cae6169043b2ad6d3094a6959b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8985698223114014, 'eval_runtime': 218.5384, 'eval_samples_per_second': 73.214, 'eval_steps_per_second': 9.152, 'epoch': 10.0}\n",
      "{'train_runtime': 73109.5664, 'train_samples_per_second': 17.508, 'train_steps_per_second': 0.137, 'train_loss': 0.8734251182556152, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.8734251182556152, metrics={'train_runtime': 73109.5664, 'train_samples_per_second': 17.508, 'train_steps_per_second': 0.137, 'total_flos': 1.5231833306038272e+17, 'train_loss': 0.8734251182556152, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Model/translate_en_hi_el/tokenizer_config.json',\n",
       " '../Model/translate_en_hi_el/special_tokens_map.json',\n",
       " '../Model/translate_en_hi_el/vocab.json',\n",
       " '../Model/translate_en_hi_el/sentencepiece.bpe.model',\n",
       " '../Model/translate_en_hi_el/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"../Model/translate_en_hi_el\")\n",
    "tokenizer.save_pretrained(\"../Model/translate_en_hi_el\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'एक पैर टूटना'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'break a leg'\n",
    "translator = pipeline(\"translation_en_to_hi\", model=\"../Model/translate_en_hi_el\")\n",
    "translator(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Διακόψτε ένα πόδι'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'break a leg'\n",
    "translator = pipeline(\"translation_en_to_el\", model=\"../Model/translate_en_hi_el\")\n",
    "translator(text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
